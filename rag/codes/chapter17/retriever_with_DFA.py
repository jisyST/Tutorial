from lazyllm.tools import Document, Retriever
from lazyllm.tools.rag import DocNode, NodeTransform
from lazyllm.tools.rag.transform import SentenceSplitter
from lazyllm import OnlineEmbeddingModule


# =============================
# 1. ÂÆö‰πâDFAËøáÊª§Âô®ÔºåÂ∞ÅË£Ö‰∏∫node transform
# =============================
class DFAFilter:
    def __init__(self, sensitive_words):
        self.root = {}
        self.end_flag = "is_end"
        for word in sensitive_words:
            self.add_word(word)

    def add_word(self, word):
        node = self.root
        for char in word:
            if char not in node:
                node[char] = {}
            node = node[char]
        node[self.end_flag] = True

    def filter(self, text, replace_char="*"):
        result = []
        start = 0
        length = len(text)

        while start < length:
            node = self.root
            i = start
            while i < length and text[i] in node:
                node = node[text[i]]
                if self.end_flag in node:
                    # ÂåπÈÖçÂà∞ÊïèÊÑüËØçÔºåÊõøÊç¢‰∏∫ÊåáÂÆöÂ≠óÁ¨¶
                    result.append(replace_char * (i - start + 1))
                    start = i + 1
                    break
                i += 1
            else:
                # Êú™ÂåπÈÖçÂà∞ÊïèÊÑüËØçÔºå‰øùÁïôÂéüÂ≠óÁ¨¶
                result.append(text[start])
                start += 1

        return ''.join(result)
   
   
# Ê≥®ÂÜå‰∏∫tranform
class DFATranform(NodeTransform):
    def __init__(self, sensitive_words):
        super(__class__, self).__init__(num_workers=1)
        self.dfafilter = DFAFilter(sensitive_words)

    def transform(self, node: DocNode, **kwargs):
        return self.dfafilter.filter(node.get_text())

    def split_text(self, text: str):
        if text == '':
            return ['']
        paragraphs = text.split(self.splitter)
        return [para for para in paragraphs]

# DFATranformÊ≥®ÂÜå‰∏∫node group
sensitive_words = ['ÂêàÂêå']  # ÈúÄË¶ÅËøáÊª§ÁöÑÊïèÊÑüËØç
Document.create_node_group(name="dfa_filter", parent="sentences", transform=DFATranform(sensitive_words))

# =============================
# 2. ÂàùÂßãÂåñÁü•ËØÜÂ∫ìÔºå ÈúÄË¶ÅËÆæÁΩÆAPI keyË∞ÉÁî®embÔºå e.g. export LAZYLLM_QWEN_API_KEY=""
# =============================

# ÂÆö‰πâÁü•ËØÜÂ∫ìË∑ØÂæÑ
law_data_path = ""
product_data_path = ""
support_data_path = ""

# ÂÜçÊ≥®ÂÜå‰∏Ä‰∏™ sentences Áî®Êù•ÂØπÊØî
Document.create_node_group('sentences', transform=SentenceSplitter, chunk_size=512, chunk_overlap=100)


# ÂàùÂßãÂåñÁü•ËØÜÂ∫ìÂØπË±°
law_knowledge_base = Document(law_data_path, name='Ê≥ïÂä°Áü•ËØÜÂ∫ì', embed=OnlineEmbeddingModule()) 
product_knowledge_base = Document(product_data_path, name='‰∫ßÂìÅÁü•ËØÜÂ∫ì', embed=OnlineEmbeddingModule())
support_knowledge_base = Document(support_data_path, name='Áî®Êà∑ÊîØÊåÅÁü•ËØÜÂ∫ì', embed=OnlineEmbeddingModule())


# =============================
# 3. ÊûÑÂª∫Â§öÁü•ËØÜÂ∫ìËÅîÂêàÂè¨Âõû
# =============================

# ÁªÑÂêàÊ≥ïÂä° + ‰∫ßÂìÅÁü•ËØÜÂ∫ìÔºåÂ§ÑÁêÜ‰∏é‰∫ßÂìÅÁõ∏ÂÖ≥ÁöÑÊ≥ïÂæãÈóÆÈ¢ò
retriever_product = Retriever(
    [law_knowledge_base, product_knowledge_base],
    group_name="dfa_filter",     # ÂèØÂàáÊç¢ sentences ÂØπÊØîÁªìÊûú
    similarity="cosine",       
    topk=1                
)

# ÁªÑÂêàÊ≥ïÂä° + ÂÆ¢ÊúçÁü•ËØÜÂ∫ìÔºåÂ§ÑÁêÜÂÆ¢Êà∑ÂêàÂêåÊäïËØâ
retriever_support = Retriever(
    [product_knowledge_base, support_knowledge_base],
    group_name="dfa_filter",
    similarity="cosine",       
    topk=1                
)

if __name__ == "__main__":
    product_question = "A‰∫ßÂìÅÂäüËÉΩÂèÇÊï∞Âíå‰∫ßÂìÅÂêàËßÑÊÄßÂ£∞Êòé"
    product_response = retriever_product(product_question)
    print()
    print(f"========== üöÄ query: {product_question } üöÄ ===========")
    print()
    print(f"========== üöÄ retrieve nodes üöÄ ===============================")
    for node in product_response:
        print(node.text)
        print("="*100)

    support_question = "B‰∫ßÂìÅÁöÑ‰∏ªË¶ÅÊàêÂàÜÁöÑÊäïËØâÁöÑÂ§ÑÁêÜÊñπÂºè"
    support_response = retriever_support(support_question)
    print()
    print(f"========== üöÄ query: {product_question } üöÄ ===========")
    print()
    print(f"========== üöÄ retrieve nodes üöÄ ===============================")
    for node in support_response:
        print(node.text)
        print("="*100)
    
